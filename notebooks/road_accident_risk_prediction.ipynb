{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0eacc0d",
   "metadata": {},
   "source": [
    "# Road Accident Risk Prediction\n",
    "\n",
    "**Competition:** Kaggle Playground Series - Season 5, Episode 10\n",
    "\n",
    "**Goal:** Predict accident risk (0-1) for different road types\n",
    "\n",
    "**Evaluation Metric:** RMSE (Root Mean Squared Error)\n",
    "\n",
    "**Target Score:** < 0.05 RMSE\n",
    "\n",
    "## Strategy\n",
    "1. Extensive Feature Engineering\n",
    "2. Multiple Model Ensemble (CatBoost, XGBoost, LightGBM)\n",
    "3. 5-Fold Cross-Validation\n",
    "4. Weighted Averaging of Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73a71db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Import Libraries\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from src.utils import create_features, encode_categoricals, get_feature_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8369698",
   "metadata": {},
   "source": [
    "## 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90fa2aca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Train shape: (517754, 14)\n",
      "Test shape: (172585, 13)\n",
      "\n",
      "First few rows:\n",
      "Train shape: (517754, 14)\n",
      "Test shape: (172585, 13)\n",
      "\n",
      "First few rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>road_type</th>\n",
       "      <th>num_lanes</th>\n",
       "      <th>curvature</th>\n",
       "      <th>speed_limit</th>\n",
       "      <th>lighting</th>\n",
       "      <th>weather</th>\n",
       "      <th>road_signs_present</th>\n",
       "      <th>public_road</th>\n",
       "      <th>time_of_day</th>\n",
       "      <th>holiday</th>\n",
       "      <th>school_season</th>\n",
       "      <th>num_reported_accidents</th>\n",
       "      <th>accident_risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>urban</td>\n",
       "      <td>2</td>\n",
       "      <td>0.06</td>\n",
       "      <td>35</td>\n",
       "      <td>daylight</td>\n",
       "      <td>rainy</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>afternoon</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>urban</td>\n",
       "      <td>4</td>\n",
       "      <td>0.99</td>\n",
       "      <td>35</td>\n",
       "      <td>daylight</td>\n",
       "      <td>clear</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>evening</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>rural</td>\n",
       "      <td>4</td>\n",
       "      <td>0.63</td>\n",
       "      <td>70</td>\n",
       "      <td>dim</td>\n",
       "      <td>clear</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>morning</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>highway</td>\n",
       "      <td>4</td>\n",
       "      <td>0.07</td>\n",
       "      <td>35</td>\n",
       "      <td>dim</td>\n",
       "      <td>rainy</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>morning</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>rural</td>\n",
       "      <td>1</td>\n",
       "      <td>0.58</td>\n",
       "      <td>60</td>\n",
       "      <td>daylight</td>\n",
       "      <td>foggy</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>evening</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.56</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id road_type  num_lanes  curvature  speed_limit  lighting weather  \\\n",
       "0   0     urban          2       0.06           35  daylight   rainy   \n",
       "1   1     urban          4       0.99           35  daylight   clear   \n",
       "2   2     rural          4       0.63           70       dim   clear   \n",
       "3   3   highway          4       0.07           35       dim   rainy   \n",
       "4   4     rural          1       0.58           60  daylight   foggy   \n",
       "\n",
       "   road_signs_present  public_road time_of_day  holiday  school_season  \\\n",
       "0               False         True   afternoon    False           True   \n",
       "1                True        False     evening     True           True   \n",
       "2               False         True     morning     True          False   \n",
       "3                True         True     morning    False          False   \n",
       "4               False        False     evening     True          False   \n",
       "\n",
       "   num_reported_accidents  accident_risk  \n",
       "0                       1           0.13  \n",
       "1                       0           0.35  \n",
       "2                       2           0.30  \n",
       "3                       1           0.21  \n",
       "4                       1           0.56  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set paths\n",
    "DATA_DIR = Path('../playground-series-s5e10')\n",
    "TRAIN_PATH = DATA_DIR / 'train.csv'\n",
    "TEST_PATH = DATA_DIR / 'test.csv'\n",
    "SUBMISSION_PATH = DATA_DIR / 'sample_submission.csv'\n",
    "\n",
    "# Load data\n",
    "print('Loading data...')\n",
    "train_df = pd.read_csv(TRAIN_PATH)\n",
    "test_df = pd.read_csv(TEST_PATH)\n",
    "sample_submission = pd.read_csv(SUBMISSION_PATH)\n",
    "\n",
    "print(f'Train shape: {train_df.shape}')\n",
    "print(f'Test shape: {test_df.shape}')\n",
    "print(f'\\nFirst few rows:')\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71e4a33e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column types:\n",
      "id                          int64\n",
      "road_type                  object\n",
      "num_lanes                   int64\n",
      "curvature                 float64\n",
      "speed_limit                 int64\n",
      "lighting                   object\n",
      "weather                    object\n",
      "road_signs_present           bool\n",
      "public_road                  bool\n",
      "time_of_day                object\n",
      "holiday                      bool\n",
      "school_season                bool\n",
      "num_reported_accidents      int64\n",
      "accident_risk             float64\n",
      "dtype: object\n",
      "\n",
      "Target statistics:\n",
      "count    517754.000000\n",
      "mean          0.352377\n",
      "std           0.166417\n",
      "min           0.000000\n",
      "25%           0.230000\n",
      "50%           0.340000\n",
      "75%           0.460000\n",
      "max           1.000000\n",
      "Name: accident_risk, dtype: float64\n",
      "\n",
      "Missing values:\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Data overview\n",
    "print('Column types:')\n",
    "print(train_df.dtypes)\n",
    "print(f'\\nTarget statistics:')\n",
    "print(train_df['accident_risk'].describe())\n",
    "print(f'\\nMissing values:')\n",
    "print(train_df.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12120a4a",
   "metadata": {},
   "source": [
    "## 2. Feature Engineering\n",
    "\n",
    "Creating advanced features to capture complex patterns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f02118e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating features...\n",
      "âœ“ Features created!\n",
      "New train shape: (517754, 30)\n",
      "âœ“ Features created!\n",
      "New train shape: (517754, 30)\n"
     ]
    }
   ],
   "source": [
    "print('Creating features...')\n",
    "train_df = create_features(train_df)\n",
    "test_df = create_features(test_df)\n",
    "print('âœ“ Features created!')\n",
    "print(f'New train shape: {train_df.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb0850a9",
   "metadata": {},
   "source": [
    "## 3. Prepare Data for Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "625f59cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total features: 28\n",
      "Categorical features: 13\n",
      "Numerical features: 15\n"
     ]
    }
   ],
   "source": [
    "# Define feature types\n",
    "TARGET = 'accident_risk'\n",
    "ID_COL = 'id'\n",
    "\n",
    "# Categorical features\n",
    "CATEGORICAL_COLS = [\n",
    "    'road_type', 'lighting', 'weather', 'road_signs_present',\n",
    "    'public_road', 'time_of_day', 'holiday', 'school_season',\n",
    "    'speed_category', 'curvature_category',\n",
    "    'road_weather', 'road_lighting', 'weather_time'\n",
    "]\n",
    "\n",
    "# Get all feature columns (excluding id and target)\n",
    "FEATURE_COLS = [col for col in train_df.columns if col not in [ID_COL, TARGET]]\n",
    "\n",
    "print(f'Total features: {len(FEATURE_COLS)}')\n",
    "print(f'Categorical features: {len(CATEGORICAL_COLS)}')\n",
    "print(f'Numerical features: {len(FEATURE_COLS) - len(CATEGORICAL_COLS)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b38f1fac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Data prepared for modeling!\n"
     ]
    }
   ],
   "source": [
    "# Encode categorical features for XGBoost and LightGBM\n",
    "def encode_categoricals(train, test, cat_cols):\n",
    "    \"\"\"Label encode categorical features.\"\"\"\n",
    "    train_encoded = train.copy()\n",
    "    test_encoded = test.copy()\n",
    "    \n",
    "    encoders = {}\n",
    "    for col in cat_cols:\n",
    "        le = LabelEncoder()\n",
    "        train_encoded[col] = le.fit_transform(train[col].astype(str))\n",
    "        test_encoded[col] = le.transform(test[col].astype(str))\n",
    "        encoders[col] = le\n",
    "    \n",
    "    return train_encoded, test_encoded, encoders\n",
    "\n",
    "# Prepare datasets\n",
    "X = train_df[FEATURE_COLS].copy()\n",
    "y = train_df[TARGET].copy()\n",
    "X_test = test_df[FEATURE_COLS].copy()\n",
    "\n",
    "# Encoded version for XGBoost/LightGBM\n",
    "X_encoded, X_test_encoded, encoders = encode_categoricals(X, X_test, CATEGORICAL_COLS)\n",
    "\n",
    "print('âœ“ Data prepared for modeling!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c7a5e24",
   "metadata": {},
   "source": [
    "## 4. Model Training with Cross-Validation\n",
    "\n",
    "Training multiple models with 5-fold CV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23f336d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting cross-validation training...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cross-validation setup\n",
    "N_FOLDS = 5\n",
    "RANDOM_STATE = 42\n",
    "kfold = KFold(n_splits=N_FOLDS, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "# Storage for predictions\n",
    "oof_catboost = np.zeros(len(X))\n",
    "oof_xgboost = np.zeros(len(X))\n",
    "oof_lightgbm = np.zeros(len(X))\n",
    "\n",
    "test_catboost = np.zeros(len(X_test))\n",
    "test_xgboost = np.zeros(len(X_test))\n",
    "test_lightgbm = np.zeros(len(X_test))\n",
    "\n",
    "fold_scores = {'catboost': [], 'xgboost': [], 'lightgbm': []}\n",
    "\n",
    "print('Starting cross-validation training...\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1ed569b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Folds:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Fold 1/5\n",
      "============================================================\n",
      "\n",
      "[1/3] Training CatBoost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Folds:   0%|          | 0/5 [00:02<?, ?it/s]\n",
      "\n"
     ]
    },
    {
     "ename": "CatBoostError",
     "evalue": "Invalid type for cat_feature[object_idx=283,feature_idx=24]=NaN : cat_features must be integer or string, real number values and NaN values should be converted to string.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mCatBoostError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m     13\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m[1/3] Training CatBoost...\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     14\u001b[39m cat_features = [X_train.columns.get_loc(col) \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m CATEGORICAL_COLS]\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m train_pool = \u001b[43mPool\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcat_features\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcat_features\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     17\u001b[39m valid_pool = Pool(X_valid, y_valid, cat_features=cat_features)\n\u001b[32m     18\u001b[39m test_pool = Pool(X_test, cat_features=cat_features)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/python/Predicting-Road-Accident-Risk/.venv/lib/python3.13/site-packages/catboost/core.py:855\u001b[39m, in \u001b[36mPool.__init__\u001b[39m\u001b[34m(self, data, label, cat_features, text_features, embedding_features, embedding_features_data, column_description, pairs, graph, delimiter, has_header, ignore_csv_quoting, weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, timestamp, feature_names, feature_tags, thread_count, log_cout, log_cerr, data_can_be_none)\u001b[39m\n\u001b[32m    849\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(feature_names, PATH_TYPES):\n\u001b[32m    850\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m CatBoostError(\n\u001b[32m    851\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mfeature_names must be None or have non-string type when the pool is created from \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    852\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mpython objects.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    853\u001b[39m             )\n\u001b[32m--> \u001b[39m\u001b[32m855\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcat_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_features_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpairs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    856\u001b[39m \u001b[43m                   \u001b[49m\u001b[43mgroup_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubgroup_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpairs_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbaseline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimestamp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_tags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthread_count\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    857\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data_can_be_none:\n\u001b[32m    858\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CatBoostError(\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[33mdata\u001b[39m\u001b[33m'\u001b[39m\u001b[33m parameter can\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt be None\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/python/Predicting-Road-Accident-Risk/.venv/lib/python3.13/site-packages/catboost/core.py:1491\u001b[39m, in \u001b[36mPool._init\u001b[39m\u001b[34m(self, data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, graph, weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, timestamp, feature_names, feature_tags, thread_count)\u001b[39m\n\u001b[32m   1489\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m feature_tags \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1490\u001b[39m     feature_tags = \u001b[38;5;28mself\u001b[39m._check_transform_tags(feature_tags, feature_names)\n\u001b[32m-> \u001b[39m\u001b[32m1491\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_init_pool\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcat_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_features_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpairs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1492\u001b[39m \u001b[43m                \u001b[49m\u001b[43mgroup_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubgroup_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpairs_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbaseline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimestamp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_tags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthread_count\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m_catboost.pyx:4329\u001b[39m, in \u001b[36m_catboost._PoolBase._init_pool\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m_catboost.pyx:4381\u001b[39m, in \u001b[36m_catboost._PoolBase._init_pool\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m_catboost.pyx:4190\u001b[39m, in \u001b[36m_catboost._PoolBase._init_features_order_layout_pool\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m_catboost.pyx:3075\u001b[39m, in \u001b[36m_catboost._set_features_order_data_pd_data_frame\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m_catboost.pyx:2953\u001b[39m, in \u001b[36m_catboost._set_features_order_data_pd_data_frame_categorical_column\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m_catboost.pyx:2898\u001b[39m, in \u001b[36m_catboost._set_hashed_cat_values\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mCatBoostError\u001b[39m: Invalid type for cat_feature[object_idx=283,feature_idx=24]=NaN : cat_features must be integer or string, real number values and NaN values should be converted to string."
     ]
    }
   ],
   "source": [
    "# Train models with progress tracking\n",
    "for fold, (train_idx, valid_idx) in enumerate(tqdm(list(kfold.split(X)), desc='Folds'), 1):\n",
    "    print(f'\\n{\"=\"*60}')\n",
    "    print(f'Fold {fold}/{N_FOLDS}')\n",
    "    print(f'{\"=\"*60}')\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_valid = X.iloc[train_idx], X.iloc[valid_idx]\n",
    "    X_train_enc, X_valid_enc = X_encoded.iloc[train_idx], X_encoded.iloc[valid_idx]\n",
    "    y_train, y_valid = y.iloc[train_idx], y.iloc[valid_idx]\n",
    "    \n",
    "    # ===== CatBoost =====\n",
    "    print('\\n[1/3] Training CatBoost...')\n",
    "    cat_features = [X_train.columns.get_loc(col) for col in CATEGORICAL_COLS]\n",
    "    \n",
    "    train_pool = Pool(X_train, y_train, cat_features=cat_features)\n",
    "    valid_pool = Pool(X_valid, y_valid, cat_features=cat_features)\n",
    "    test_pool = Pool(X_test, cat_features=cat_features)\n",
    "    \n",
    "    cb_model = CatBoostRegressor(\n",
    "        iterations=3000,\n",
    "        learning_rate=0.03,\n",
    "        depth=8,\n",
    "        loss_function='RMSE',\n",
    "        eval_metric='RMSE',\n",
    "        subsample=0.8,\n",
    "        colsample_bylevel=0.8,\n",
    "        random_seed=RANDOM_STATE + fold,\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    cb_model.fit(\n",
    "        train_pool,\n",
    "        eval_set=valid_pool,\n",
    "        early_stopping_rounds=200,\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    oof_catboost[valid_idx] = cb_model.predict(valid_pool)\n",
    "    test_catboost += cb_model.predict(test_pool) / N_FOLDS\n",
    "    \n",
    "    cb_score = mean_squared_error(y_valid, oof_catboost[valid_idx], squared=False)\n",
    "    fold_scores['catboost'].append(cb_score)\n",
    "    print(f'  CatBoost RMSE: {cb_score:.5f}')\n",
    "    \n",
    "    # ===== XGBoost =====\n",
    "    print('\\n[2/3] Training XGBoost...')\n",
    "    xgb_model = XGBRegressor(\n",
    "        n_estimators=3000,\n",
    "        learning_rate=0.03,\n",
    "        max_depth=8,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        reg_alpha=0.1,\n",
    "        reg_lambda=0.1,\n",
    "        random_state=RANDOM_STATE + fold,\n",
    "        tree_method='hist',\n",
    "        enable_categorical=True\n",
    "    )\n",
    "    \n",
    "    xgb_model.fit(\n",
    "        X_train_enc, y_train,\n",
    "        eval_set=[(X_valid_enc, y_valid)],\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    oof_xgboost[valid_idx] = xgb_model.predict(X_valid_enc)\n",
    "    test_xgboost += xgb_model.predict(X_test_encoded) / N_FOLDS\n",
    "    \n",
    "    xgb_score = mean_squared_error(y_valid, oof_xgboost[valid_idx], squared=False)\n",
    "    fold_scores['xgboost'].append(xgb_score)\n",
    "    print(f'  XGBoost RMSE: {xgb_score:.5f}')\n",
    "    \n",
    "    # ===== LightGBM =====\n",
    "    print('\\n[3/3] Training LightGBM...')\n",
    "    lgb_model = LGBMRegressor(\n",
    "        n_estimators=3000,\n",
    "        learning_rate=0.03,\n",
    "        num_leaves=64,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        reg_alpha=0.1,\n",
    "        reg_lambda=0.1,\n",
    "        random_state=RANDOM_STATE + fold,\n",
    "        verbose=-1\n",
    "    )\n",
    "    \n",
    "    lgb_model.fit(\n",
    "        X_train_enc, y_train,\n",
    "        eval_set=[(X_valid_enc, y_valid)],\n",
    "        callbacks=[]\n",
    "    )\n",
    "    \n",
    "    oof_lightgbm[valid_idx] = lgb_model.predict(X_valid_enc)\n",
    "    test_lightgbm += lgb_model.predict(X_test_encoded) / N_FOLDS\n",
    "    \n",
    "    lgb_score = mean_squared_error(y_valid, oof_lightgbm[valid_idx], squared=False)\n",
    "    fold_scores['lightgbm'].append(lgb_score)\n",
    "    print(f'  LightGBM RMSE: {lgb_score:.5f}')\n",
    "\n",
    "print(f'\\n{\"=\"*60}')\n",
    "print('Training complete!')\n",
    "print(f'{\"=\"*60}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eefd2d3f",
   "metadata": {},
   "source": [
    "## 5. Cross-Validation Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62818b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate CV scores\n",
    "cv_catboost = mean_squared_error(y, oof_catboost, squared=False)\n",
    "cv_xgboost = mean_squared_error(y, oof_xgboost, squared=False)\n",
    "cv_lightgbm = mean_squared_error(y, oof_lightgbm, squared=False)\n",
    "\n",
    "print('\\n' + '='*60)\n",
    "print('CROSS-VALIDATION RESULTS')\n",
    "print('='*60)\n",
    "print(f'CatBoost  CV RMSE: {cv_catboost:.5f}')\n",
    "print(f'XGBoost   CV RMSE: {cv_xgboost:.5f}')\n",
    "print(f'LightGBM  CV RMSE: {cv_lightgbm:.5f}')\n",
    "print('='*60)\n",
    "\n",
    "# Fold-wise scores\n",
    "print('\\nFold-wise scores:')\n",
    "fold_df = pd.DataFrame(fold_scores)\n",
    "fold_df.index = [f'Fold {i+1}' for i in range(N_FOLDS)]\n",
    "fold_df.loc['Mean'] = fold_df.mean()\n",
    "fold_df.loc['Std'] = fold_df.std()\n",
    "print(fold_df.round(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282d62f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot CV scores\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "fold_df.iloc[:-2].plot(kind='bar', ax=ax, width=0.8)\n",
    "ax.set_title('Cross-Validation RMSE by Fold', fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('Fold', fontsize=12)\n",
    "ax.set_ylabel('RMSE', fontsize=12)\n",
    "ax.legend(title='Model', fontsize=10)\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "plt.xticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8390128b",
   "metadata": {},
   "source": [
    "## 6. Ensemble Predictions\n",
    "\n",
    "Combining predictions from all three models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81414dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try different ensemble weights\n",
    "print('Testing ensemble weights...\\n')\n",
    "\n",
    "best_score = float('inf')\n",
    "best_weights = None\n",
    "\n",
    "# Test different weight combinations\n",
    "weight_options = [\n",
    "    (0.4, 0.3, 0.3),  # Equal-ish\n",
    "    (0.5, 0.25, 0.25),  # Favor CatBoost\n",
    "    (0.34, 0.33, 0.33),  # Exactly equal\n",
    "    (0.6, 0.2, 0.2),  # Heavy CatBoost\n",
    "    (0.45, 0.35, 0.2),  # Favor top 2\n",
    "]\n",
    "\n",
    "for weights in weight_options:\n",
    "    w_cb, w_xgb, w_lgb = weights\n",
    "    \n",
    "    oof_ensemble = (\n",
    "        w_cb * oof_catboost +\n",
    "        w_xgb * oof_xgboost +\n",
    "        w_lgb * oof_lightgbm\n",
    "    )\n",
    "    \n",
    "    ensemble_score = mean_squared_error(y, oof_ensemble, squared=False)\n",
    "    \n",
    "    print(f'Weights {weights}: RMSE = {ensemble_score:.5f}')\n",
    "    \n",
    "    if ensemble_score < best_score:\n",
    "        best_score = ensemble_score\n",
    "        best_weights = weights\n",
    "\n",
    "print(f'\\nâœ“ Best weights: {best_weights}')\n",
    "print(f'âœ“ Best ensemble CV RMSE: {best_score:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9495ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create final ensemble predictions\n",
    "w_cb, w_xgb, w_lgb = best_weights\n",
    "\n",
    "test_ensemble = (\n",
    "    w_cb * test_catboost +\n",
    "    w_xgb * test_xgboost +\n",
    "    w_lgb * test_lightgbm\n",
    ")\n",
    "\n",
    "# Clip predictions to valid range [0, 1]\n",
    "test_ensemble = np.clip(test_ensemble, 0, 1)\n",
    "\n",
    "print(f'Final test predictions:')\n",
    "print(f'  Min: {test_ensemble.min():.4f}')\n",
    "print(f'  Max: {test_ensemble.max():.4f}')\n",
    "print(f'  Mean: {test_ensemble.mean():.4f}')\n",
    "print(f'  Median: {np.median(test_ensemble):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0f2743",
   "metadata": {},
   "source": [
    "## 7. Create Submission File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b536df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create submission\n",
    "submission = sample_submission.copy()\n",
    "submission['accident_risk'] = test_ensemble\n",
    "\n",
    "# Save to file\n",
    "output_path = Path('../submission.csv')\n",
    "submission.to_csv(output_path, index=False)\n",
    "\n",
    "print('âœ“ Submission file created successfully!')\n",
    "print(f'  Location: {output_path.resolve()}')\n",
    "print(f'  Shape: {submission.shape}')\n",
    "print(f'\\nFirst few rows:')\n",
    "print(submission.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e782ba9",
   "metadata": {},
   "source": [
    "## 8. Analysis & Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a912c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot prediction distributions\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Training target distribution\n",
    "axes[0, 0].hist(y, bins=50, alpha=0.7, color='blue', edgecolor='black')\n",
    "axes[0, 0].set_title('Training Target Distribution', fontweight='bold')\n",
    "axes[0, 0].set_xlabel('Accident Risk')\n",
    "axes[0, 0].set_ylabel('Frequency')\n",
    "\n",
    "# Test predictions distribution\n",
    "axes[0, 1].hist(test_ensemble, bins=50, alpha=0.7, color='green', edgecolor='black')\n",
    "axes[0, 1].set_title('Test Predictions Distribution', fontweight='bold')\n",
    "axes[0, 1].set_xlabel('Predicted Accident Risk')\n",
    "axes[0, 1].set_ylabel('Frequency')\n",
    "\n",
    "# OOF vs Actual scatter\n",
    "oof_ensemble = (\n",
    "    w_cb * oof_catboost +\n",
    "    w_xgb * oof_xgboost +\n",
    "    w_lgb * oof_lightgbm\n",
    ")\n",
    "axes[1, 0].scatter(y, oof_ensemble, alpha=0.3, s=1)\n",
    "axes[1, 0].plot([0, 1], [0, 1], 'r--', lw=2)\n",
    "axes[1, 0].set_title('OOF Predictions vs Actual', fontweight='bold')\n",
    "axes[1, 0].set_xlabel('Actual Accident Risk')\n",
    "axes[1, 0].set_ylabel('Predicted Accident Risk')\n",
    "\n",
    "# Model comparison\n",
    "model_scores = pd.Series({\n",
    "    'CatBoost': cv_catboost,\n",
    "    'XGBoost': cv_xgboost,\n",
    "    'LightGBM': cv_lightgbm,\n",
    "    'Ensemble': best_score\n",
    "})\n",
    "model_scores.plot(kind='bar', ax=axes[1, 1], color=['skyblue', 'lightgreen', 'lightcoral', 'gold'])\n",
    "axes[1, 1].set_title('Model Performance Comparison', fontweight='bold')\n",
    "axes[1, 1].set_ylabel('CV RMSE')\n",
    "axes[1, 1].set_xlabel('Model')\n",
    "axes[1, 1].grid(axis='y', alpha=0.3)\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a8d64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residual analysis\n",
    "residuals = y - oof_ensemble\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Residual distribution\n",
    "axes[0].hist(residuals, bins=50, alpha=0.7, color='purple', edgecolor='black')\n",
    "axes[0].set_title('Residual Distribution', fontweight='bold')\n",
    "axes[0].set_xlabel('Residual (Actual - Predicted)')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "axes[0].axvline(0, color='red', linestyle='--', linewidth=2)\n",
    "\n",
    "# Residual scatter\n",
    "axes[1].scatter(oof_ensemble, residuals, alpha=0.3, s=1)\n",
    "axes[1].axhline(0, color='red', linestyle='--', linewidth=2)\n",
    "axes[1].set_title('Residual Plot', fontweight='bold')\n",
    "axes[1].set_xlabel('Predicted Accident Risk')\n",
    "axes[1].set_ylabel('Residual')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f'Residual statistics:')\n",
    "print(f'  Mean: {residuals.mean():.6f}')\n",
    "print(f'  Std: {residuals.std():.6f}')\n",
    "print(f'  Min: {residuals.min():.6f}')\n",
    "print(f'  Max: {residuals.max():.6f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41b8762",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "**Final Results:**\n",
    "- Ensemble model combining CatBoost, XGBoost, and LightGBM\n",
    "- 5-fold cross-validation\n",
    "- Extensive feature engineering (27 features)\n",
    "- Submission file created: `submission.csv`\n",
    "\n",
    "**Next Steps:**\n",
    "1. Upload submission to Kaggle\n",
    "2. Monitor leaderboard score\n",
    "3. If score > 0.05, iterate with:\n",
    "   - More feature engineering\n",
    "   - Hyperparameter tuning\n",
    "   - Include original dataset\n",
    "   - Advanced stacking techniques"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
