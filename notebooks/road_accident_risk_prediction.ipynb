{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0eacc0d",
   "metadata": {},
   "source": [
    "# Road Accident Risk Prediction\n",
    "\n",
    "**Competition:** Kaggle Playground Series - Season 5, Episode 10\n",
    "\n",
    "**Goal:** Predict accident risk (0-1) for different road types\n",
    "\n",
    "**Evaluation Metric:** RMSE (Root Mean Squared Error)\n",
    "\n",
    "**Target Score:** < 0.05 RMSE\n",
    "\n",
    "## Strategy\n",
    "1. Extensive Feature Engineering\n",
    "2. Multiple Model Ensemble (CatBoost, XGBoost, LightGBM)\n",
    "3. 5-Fold Cross-Validation\n",
    "4. Weighted Averaging of Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73a71db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "print('✓ Libraries imported successfully!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8369698",
   "metadata": {},
   "source": [
    "## 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90fa2aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set paths\n",
    "DATA_DIR = Path('../playground-series-s5e10')\n",
    "TRAIN_PATH = DATA_DIR / 'train.csv'\n",
    "TEST_PATH = DATA_DIR / 'test.csv'\n",
    "SUBMISSION_PATH = DATA_DIR / 'sample_submission.csv'\n",
    "\n",
    "# Load data\n",
    "print('Loading data...')\n",
    "train_df = pd.read_csv(TRAIN_PATH)\n",
    "test_df = pd.read_csv(TEST_PATH)\n",
    "sample_submission = pd.read_csv(SUBMISSION_PATH)\n",
    "\n",
    "print(f'Train shape: {train_df.shape}')\n",
    "print(f'Test shape: {test_df.shape}')\n",
    "print(f'\\nFirst few rows:')\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e4a33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data overview\n",
    "print('Column types:')\n",
    "print(train_df.dtypes)\n",
    "print(f'\\nTarget statistics:')\n",
    "print(train_df['accident_risk'].describe())\n",
    "print(f'\\nMissing values:')\n",
    "print(train_df.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12120a4a",
   "metadata": {},
   "source": [
    "## 2. Feature Engineering\n",
    "\n",
    "Creating advanced features to capture complex patterns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f02118e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features(df):\n",
    "    \"\"\"Create advanced features for the model.\"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Interaction features\n",
    "    df['speed_per_lane'] = df['speed_limit'] / df['num_lanes']\n",
    "    df['curvature_speed'] = df['curvature'] * df['speed_limit']\n",
    "    df['accidents_per_lane'] = df['num_reported_accidents'] / df['num_lanes']\n",
    "    \n",
    "    # Boolean combinations\n",
    "    df['risky_conditions'] = (\n",
    "        (df['weather'] == 'rainy') & \n",
    "        (df['lighting'] == 'dim')\n",
    "    ).astype(int)\n",
    "    \n",
    "    df['peak_holiday'] = (\n",
    "        (df['holiday'] == True) & \n",
    "        (df['time_of_day'].isin(['evening', 'afternoon']))\n",
    "    ).astype(int)\n",
    "    \n",
    "    df['school_morning'] = (\n",
    "        (df['school_season'] == True) & \n",
    "        (df['time_of_day'] == 'morning')\n",
    "    ).astype(int)\n",
    "    \n",
    "    # Risk score combinations\n",
    "    df['high_speed_curve'] = (\n",
    "        (df['speed_limit'] > 50) & \n",
    "        (df['curvature'] > 0.5)\n",
    "    ).astype(int)\n",
    "    \n",
    "    df['no_signs_bad_weather'] = (\n",
    "        (df['road_signs_present'] == False) & \n",
    "        (df['weather'] != 'clear')\n",
    "    ).astype(int)\n",
    "    \n",
    "    # Polynomial features for continuous variables\n",
    "    df['curvature_squared'] = df['curvature'] ** 2\n",
    "    df['speed_squared'] = df['speed_limit'] ** 2\n",
    "    df['accidents_squared'] = df['num_reported_accidents'] ** 2\n",
    "    \n",
    "    # Binned features\n",
    "    df['speed_category'] = pd.cut(df['speed_limit'], \n",
    "                                    bins=[0, 35, 50, 70], \n",
    "                                    labels=['low', 'medium', 'high'])\n",
    "    \n",
    "    df['curvature_category'] = pd.cut(df['curvature'], \n",
    "                                       bins=[0, 0.33, 0.66, 1.0], \n",
    "                                       labels=['straight', 'moderate', 'sharp'])\n",
    "    \n",
    "    # Combined categorical features\n",
    "    df['road_weather'] = df['road_type'] + '_' + df['weather']\n",
    "    df['road_lighting'] = df['road_type'] + '_' + df['lighting']\n",
    "    df['weather_time'] = df['weather'] + '_' + df['time_of_day']\n",
    "    \n",
    "    return df\n",
    "\n",
    "print('Creating features...')\n",
    "train_df = create_features(train_df)\n",
    "test_df = create_features(test_df)\n",
    "print('✓ Features created!')\n",
    "print(f'New train shape: {train_df.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb0850a9",
   "metadata": {},
   "source": [
    "## 3. Prepare Data for Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625f59cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define feature types\n",
    "TARGET = 'accident_risk'\n",
    "ID_COL = 'id'\n",
    "\n",
    "# Categorical features\n",
    "CATEGORICAL_COLS = [\n",
    "    'road_type', 'lighting', 'weather', 'road_signs_present',\n",
    "    'public_road', 'time_of_day', 'holiday', 'school_season',\n",
    "    'speed_category', 'curvature_category',\n",
    "    'road_weather', 'road_lighting', 'weather_time'\n",
    "]\n",
    "\n",
    "# Get all feature columns (excluding id and target)\n",
    "FEATURE_COLS = [col for col in train_df.columns if col not in [ID_COL, TARGET]]\n",
    "\n",
    "print(f'Total features: {len(FEATURE_COLS)}')\n",
    "print(f'Categorical features: {len(CATEGORICAL_COLS)}')\n",
    "print(f'Numerical features: {len(FEATURE_COLS) - len(CATEGORICAL_COLS)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38f1fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical features for XGBoost and LightGBM\n",
    "def encode_categoricals(train, test, cat_cols):\n",
    "    \"\"\"Label encode categorical features.\"\"\"\n",
    "    train_encoded = train.copy()\n",
    "    test_encoded = test.copy()\n",
    "    \n",
    "    encoders = {}\n",
    "    for col in cat_cols:\n",
    "        le = LabelEncoder()\n",
    "        train_encoded[col] = le.fit_transform(train[col].astype(str))\n",
    "        test_encoded[col] = le.transform(test[col].astype(str))\n",
    "        encoders[col] = le\n",
    "    \n",
    "    return train_encoded, test_encoded, encoders\n",
    "\n",
    "# Prepare datasets\n",
    "X = train_df[FEATURE_COLS].copy()\n",
    "y = train_df[TARGET].copy()\n",
    "X_test = test_df[FEATURE_COLS].copy()\n",
    "\n",
    "# Encoded version for XGBoost/LightGBM\n",
    "X_encoded, X_test_encoded, encoders = encode_categoricals(X, X_test, CATEGORICAL_COLS)\n",
    "\n",
    "print('✓ Data prepared for modeling!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c7a5e24",
   "metadata": {},
   "source": [
    "## 4. Model Training with Cross-Validation\n",
    "\n",
    "Training multiple models with 5-fold CV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f336d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation setup\n",
    "N_FOLDS = 5\n",
    "RANDOM_STATE = 42\n",
    "kfold = KFold(n_splits=N_FOLDS, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "# Storage for predictions\n",
    "oof_catboost = np.zeros(len(X))\n",
    "oof_xgboost = np.zeros(len(X))\n",
    "oof_lightgbm = np.zeros(len(X))\n",
    "\n",
    "test_catboost = np.zeros(len(X_test))\n",
    "test_xgboost = np.zeros(len(X_test))\n",
    "test_lightgbm = np.zeros(len(X_test))\n",
    "\n",
    "fold_scores = {'catboost': [], 'xgboost': [], 'lightgbm': []}\n",
    "\n",
    "print('Starting cross-validation training...\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed569b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train models with progress tracking\n",
    "for fold, (train_idx, valid_idx) in enumerate(tqdm(list(kfold.split(X)), desc='Folds'), 1):\n",
    "    print(f'\\n{\"=\"*60}')\n",
    "    print(f'Fold {fold}/{N_FOLDS}')\n",
    "    print(f'{\"=\"*60}')\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_valid = X.iloc[train_idx], X.iloc[valid_idx]\n",
    "    X_train_enc, X_valid_enc = X_encoded.iloc[train_idx], X_encoded.iloc[valid_idx]\n",
    "    y_train, y_valid = y.iloc[train_idx], y.iloc[valid_idx]\n",
    "    \n",
    "    # ===== CatBoost =====\n",
    "    print('\\n[1/3] Training CatBoost...')\n",
    "    cat_features = [X_train.columns.get_loc(col) for col in CATEGORICAL_COLS]\n",
    "    \n",
    "    train_pool = Pool(X_train, y_train, cat_features=cat_features)\n",
    "    valid_pool = Pool(X_valid, y_valid, cat_features=cat_features)\n",
    "    test_pool = Pool(X_test, cat_features=cat_features)\n",
    "    \n",
    "    cb_model = CatBoostRegressor(\n",
    "        iterations=3000,\n",
    "        learning_rate=0.03,\n",
    "        depth=8,\n",
    "        loss_function='RMSE',\n",
    "        eval_metric='RMSE',\n",
    "        subsample=0.8,\n",
    "        colsample_bylevel=0.8,\n",
    "        random_seed=RANDOM_STATE + fold,\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    cb_model.fit(\n",
    "        train_pool,\n",
    "        eval_set=valid_pool,\n",
    "        early_stopping_rounds=200,\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    oof_catboost[valid_idx] = cb_model.predict(valid_pool)\n",
    "    test_catboost += cb_model.predict(test_pool) / N_FOLDS\n",
    "    \n",
    "    cb_score = mean_squared_error(y_valid, oof_catboost[valid_idx], squared=False)\n",
    "    fold_scores['catboost'].append(cb_score)\n",
    "    print(f'  CatBoost RMSE: {cb_score:.5f}')\n",
    "    \n",
    "    # ===== XGBoost =====\n",
    "    print('\\n[2/3] Training XGBoost...')\n",
    "    xgb_model = XGBRegressor(\n",
    "        n_estimators=3000,\n",
    "        learning_rate=0.03,\n",
    "        max_depth=8,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        reg_alpha=0.1,\n",
    "        reg_lambda=0.1,\n",
    "        random_state=RANDOM_STATE + fold,\n",
    "        tree_method='hist',\n",
    "        enable_categorical=True\n",
    "    )\n",
    "    \n",
    "    xgb_model.fit(\n",
    "        X_train_enc, y_train,\n",
    "        eval_set=[(X_valid_enc, y_valid)],\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    oof_xgboost[valid_idx] = xgb_model.predict(X_valid_enc)\n",
    "    test_xgboost += xgb_model.predict(X_test_encoded) / N_FOLDS\n",
    "    \n",
    "    xgb_score = mean_squared_error(y_valid, oof_xgboost[valid_idx], squared=False)\n",
    "    fold_scores['xgboost'].append(xgb_score)\n",
    "    print(f'  XGBoost RMSE: {xgb_score:.5f}')\n",
    "    \n",
    "    # ===== LightGBM =====\n",
    "    print('\\n[3/3] Training LightGBM...')\n",
    "    lgb_model = LGBMRegressor(\n",
    "        n_estimators=3000,\n",
    "        learning_rate=0.03,\n",
    "        num_leaves=64,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        reg_alpha=0.1,\n",
    "        reg_lambda=0.1,\n",
    "        random_state=RANDOM_STATE + fold,\n",
    "        verbose=-1\n",
    "    )\n",
    "    \n",
    "    lgb_model.fit(\n",
    "        X_train_enc, y_train,\n",
    "        eval_set=[(X_valid_enc, y_valid)],\n",
    "        callbacks=[]\n",
    "    )\n",
    "    \n",
    "    oof_lightgbm[valid_idx] = lgb_model.predict(X_valid_enc)\n",
    "    test_lightgbm += lgb_model.predict(X_test_encoded) / N_FOLDS\n",
    "    \n",
    "    lgb_score = mean_squared_error(y_valid, oof_lightgbm[valid_idx], squared=False)\n",
    "    fold_scores['lightgbm'].append(lgb_score)\n",
    "    print(f'  LightGBM RMSE: {lgb_score:.5f}')\n",
    "\n",
    "print(f'\\n{\"=\"*60}')\n",
    "print('Training complete!')\n",
    "print(f'{\"=\"*60}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eefd2d3f",
   "metadata": {},
   "source": [
    "## 5. Cross-Validation Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62818b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate CV scores\n",
    "cv_catboost = mean_squared_error(y, oof_catboost, squared=False)\n",
    "cv_xgboost = mean_squared_error(y, oof_xgboost, squared=False)\n",
    "cv_lightgbm = mean_squared_error(y, oof_lightgbm, squared=False)\n",
    "\n",
    "print('\\n' + '='*60)\n",
    "print('CROSS-VALIDATION RESULTS')\n",
    "print('='*60)\n",
    "print(f'CatBoost  CV RMSE: {cv_catboost:.5f}')\n",
    "print(f'XGBoost   CV RMSE: {cv_xgboost:.5f}')\n",
    "print(f'LightGBM  CV RMSE: {cv_lightgbm:.5f}')\n",
    "print('='*60)\n",
    "\n",
    "# Fold-wise scores\n",
    "print('\\nFold-wise scores:')\n",
    "fold_df = pd.DataFrame(fold_scores)\n",
    "fold_df.index = [f'Fold {i+1}' for i in range(N_FOLDS)]\n",
    "fold_df.loc['Mean'] = fold_df.mean()\n",
    "fold_df.loc['Std'] = fold_df.std()\n",
    "print(fold_df.round(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282d62f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot CV scores\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "fold_df.iloc[:-2].plot(kind='bar', ax=ax, width=0.8)\n",
    "ax.set_title('Cross-Validation RMSE by Fold', fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('Fold', fontsize=12)\n",
    "ax.set_ylabel('RMSE', fontsize=12)\n",
    "ax.legend(title='Model', fontsize=10)\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "plt.xticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8390128b",
   "metadata": {},
   "source": [
    "## 6. Ensemble Predictions\n",
    "\n",
    "Combining predictions from all three models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81414dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try different ensemble weights\n",
    "print('Testing ensemble weights...\\n')\n",
    "\n",
    "best_score = float('inf')\n",
    "best_weights = None\n",
    "\n",
    "# Test different weight combinations\n",
    "weight_options = [\n",
    "    (0.4, 0.3, 0.3),  # Equal-ish\n",
    "    (0.5, 0.25, 0.25),  # Favor CatBoost\n",
    "    (0.34, 0.33, 0.33),  # Exactly equal\n",
    "    (0.6, 0.2, 0.2),  # Heavy CatBoost\n",
    "    (0.45, 0.35, 0.2),  # Favor top 2\n",
    "]\n",
    "\n",
    "for weights in weight_options:\n",
    "    w_cb, w_xgb, w_lgb = weights\n",
    "    \n",
    "    oof_ensemble = (\n",
    "        w_cb * oof_catboost +\n",
    "        w_xgb * oof_xgboost +\n",
    "        w_lgb * oof_lightgbm\n",
    "    )\n",
    "    \n",
    "    ensemble_score = mean_squared_error(y, oof_ensemble, squared=False)\n",
    "    \n",
    "    print(f'Weights {weights}: RMSE = {ensemble_score:.5f}')\n",
    "    \n",
    "    if ensemble_score < best_score:\n",
    "        best_score = ensemble_score\n",
    "        best_weights = weights\n",
    "\n",
    "print(f'\\n✓ Best weights: {best_weights}')\n",
    "print(f'✓ Best ensemble CV RMSE: {best_score:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9495ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create final ensemble predictions\n",
    "w_cb, w_xgb, w_lgb = best_weights\n",
    "\n",
    "test_ensemble = (\n",
    "    w_cb * test_catboost +\n",
    "    w_xgb * test_xgboost +\n",
    "    w_lgb * test_lightgbm\n",
    ")\n",
    "\n",
    "# Clip predictions to valid range [0, 1]\n",
    "test_ensemble = np.clip(test_ensemble, 0, 1)\n",
    "\n",
    "print(f'Final test predictions:')\n",
    "print(f'  Min: {test_ensemble.min():.4f}')\n",
    "print(f'  Max: {test_ensemble.max():.4f}')\n",
    "print(f'  Mean: {test_ensemble.mean():.4f}')\n",
    "print(f'  Median: {np.median(test_ensemble):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0f2743",
   "metadata": {},
   "source": [
    "## 7. Create Submission File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b536df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create submission\n",
    "submission = sample_submission.copy()\n",
    "submission['accident_risk'] = test_ensemble\n",
    "\n",
    "# Save to file\n",
    "output_path = Path('../submission.csv')\n",
    "submission.to_csv(output_path, index=False)\n",
    "\n",
    "print('✓ Submission file created successfully!')\n",
    "print(f'  Location: {output_path.resolve()}')\n",
    "print(f'  Shape: {submission.shape}')\n",
    "print(f'\\nFirst few rows:')\n",
    "print(submission.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e782ba9",
   "metadata": {},
   "source": [
    "## 8. Analysis & Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a912c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot prediction distributions\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Training target distribution\n",
    "axes[0, 0].hist(y, bins=50, alpha=0.7, color='blue', edgecolor='black')\n",
    "axes[0, 0].set_title('Training Target Distribution', fontweight='bold')\n",
    "axes[0, 0].set_xlabel('Accident Risk')\n",
    "axes[0, 0].set_ylabel('Frequency')\n",
    "\n",
    "# Test predictions distribution\n",
    "axes[0, 1].hist(test_ensemble, bins=50, alpha=0.7, color='green', edgecolor='black')\n",
    "axes[0, 1].set_title('Test Predictions Distribution', fontweight='bold')\n",
    "axes[0, 1].set_xlabel('Predicted Accident Risk')\n",
    "axes[0, 1].set_ylabel('Frequency')\n",
    "\n",
    "# OOF vs Actual scatter\n",
    "oof_ensemble = (\n",
    "    w_cb * oof_catboost +\n",
    "    w_xgb * oof_xgboost +\n",
    "    w_lgb * oof_lightgbm\n",
    ")\n",
    "axes[1, 0].scatter(y, oof_ensemble, alpha=0.3, s=1)\n",
    "axes[1, 0].plot([0, 1], [0, 1], 'r--', lw=2)\n",
    "axes[1, 0].set_title('OOF Predictions vs Actual', fontweight='bold')\n",
    "axes[1, 0].set_xlabel('Actual Accident Risk')\n",
    "axes[1, 0].set_ylabel('Predicted Accident Risk')\n",
    "\n",
    "# Model comparison\n",
    "model_scores = pd.Series({\n",
    "    'CatBoost': cv_catboost,\n",
    "    'XGBoost': cv_xgboost,\n",
    "    'LightGBM': cv_lightgbm,\n",
    "    'Ensemble': best_score\n",
    "})\n",
    "model_scores.plot(kind='bar', ax=axes[1, 1], color=['skyblue', 'lightgreen', 'lightcoral', 'gold'])\n",
    "axes[1, 1].set_title('Model Performance Comparison', fontweight='bold')\n",
    "axes[1, 1].set_ylabel('CV RMSE')\n",
    "axes[1, 1].set_xlabel('Model')\n",
    "axes[1, 1].grid(axis='y', alpha=0.3)\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a8d64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residual analysis\n",
    "residuals = y - oof_ensemble\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Residual distribution\n",
    "axes[0].hist(residuals, bins=50, alpha=0.7, color='purple', edgecolor='black')\n",
    "axes[0].set_title('Residual Distribution', fontweight='bold')\n",
    "axes[0].set_xlabel('Residual (Actual - Predicted)')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "axes[0].axvline(0, color='red', linestyle='--', linewidth=2)\n",
    "\n",
    "# Residual scatter\n",
    "axes[1].scatter(oof_ensemble, residuals, alpha=0.3, s=1)\n",
    "axes[1].axhline(0, color='red', linestyle='--', linewidth=2)\n",
    "axes[1].set_title('Residual Plot', fontweight='bold')\n",
    "axes[1].set_xlabel('Predicted Accident Risk')\n",
    "axes[1].set_ylabel('Residual')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f'Residual statistics:')\n",
    "print(f'  Mean: {residuals.mean():.6f}')\n",
    "print(f'  Std: {residuals.std():.6f}')\n",
    "print(f'  Min: {residuals.min():.6f}')\n",
    "print(f'  Max: {residuals.max():.6f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41b8762",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "**Final Results:**\n",
    "- Ensemble model combining CatBoost, XGBoost, and LightGBM\n",
    "- 5-fold cross-validation\n",
    "- Extensive feature engineering (27 features)\n",
    "- Submission file created: `submission.csv`\n",
    "\n",
    "**Next Steps:**\n",
    "1. Upload submission to Kaggle\n",
    "2. Monitor leaderboard score\n",
    "3. If score > 0.05, iterate with:\n",
    "   - More feature engineering\n",
    "   - Hyperparameter tuning\n",
    "   - Include original dataset\n",
    "   - Advanced stacking techniques"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
